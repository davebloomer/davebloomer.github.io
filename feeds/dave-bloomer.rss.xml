<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Dave Bloomer - Dave Bloomer</title><link>https://davebloomer.github.io/</link><description>Data Science Sandbox</description><lastBuildDate>Sun, 06 Jun 2021 00:00:00 +0100</lastBuildDate><item><title>Artificially Reducing Intelligence (Pt. 1)</title><link>https://davebloomer.github.io/artificially-reducing-intelligence-pt1.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Carrying on with the fermentation theme, my long term goal is to use machine learning to design an (possibly) awesome beer recipe. However, in order to train a model, we need some data linking to recipes to consumer opinions. While there are lots of online resources for opinions, commercial beer recipes are often guarded secrets, and it's especially rare that they are shared following a structured data format. One (sort of) exception to this rule is the BrewDog DIY Dog. The catalogue of all BrewDog recipes is published anually in pdf format allowing homebrewers to have a go themselves. While recipes are largely written in a consistent way, some challenges existed in parsing the data to a machine readable format - and a couple of different libraries (PyPDF2 and tabula-py) were required.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Sun, 06 Jun 2021 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2021-06-06:/artificially-reducing-intelligence-pt1.html</guid><category>python</category><category>webscraping</category><category>fermentation</category></item><item><title>Visualising Water Profiles</title><link>https://davebloomer.github.io/water-profiles.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Here's the first post of a few planned within a fermentation series. One of the key ingredients to any drink, whether beer, kombucha, hop water etc is of course water, and not all waters are created equal. If water is the base of a drink, some flavours are better complimenteted by a blank canvas, while minerality can be used to make certain flavours pop. A common analogy is when cooking, flavours are brought out using salt, vinegar and other condiments. Getting this balance right can make all difference. Conversely if you're starting point is too rich in these properties, it's probably worth considering diluting, or even switching out for low-minerality bottled water. A common recommendation is to look in to the properties of your water at home, investigate what the properties of your water are, and see where you can go from there to tweak your water profile using common additives such as gypsum, baking soda and salt.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Sun, 11 Apr 2021 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2021-04-11:/water-profiles.html</guid><category>python</category><category>visualisation</category><category>pandas</category><category>fermentation</category></item><item><title>Reactive</title><link>https://davebloomer.github.io/reactivate.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;It's been a while since I've had the chance to post, and that's mostly because I switched from pursuing a career change in to data science, to actually beginning a full-time career (in addition to finishing my Masters degree in Data Science from Birkbeck). However, now that my thesis is handed in, I'm keen to get back to exploring why I became interested in using Python and Data Science to begin with. I've also picked up a new hobby during lockdown, fermenting homemade beer and kombucha, so have started to explore some projects in this space too. Until next time..&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Sun, 28 Feb 2021 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2021-02-28:/reactivate.html</guid><category>misc</category></item><item><title>Python User Interface (Jupyter Widgets)</title><link>https://davebloomer.github.io/jupyter-ui.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;With exams over I can finally start concentrating on &lt;del&gt;finding a job&lt;/del&gt; posting more to my blog. I have been working on a Sudoku solver and puzzle generator over the past couple of months and was keen to write this up now I have the time, but I felt frustrated that the code wasn't really going to be of use without some form of web based user interface.&lt;/p&gt;
&lt;h3 id="A-Web-Based-Python-UI?"&gt;A Web Based Python UI?&lt;a class="anchor-link" href="#A-Web-Based-Python-UI?"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;After exploring multiple options I'm still not convinced there is an ideal solution that doesn't involve learning Javascript or migrating the site from GitHub. If I'm overlooking something obvious please leave a comment. The best solution I can find is to impliment a degree of interactivity using Jupyter Notebook Widgets, unfortunately this interactivity is lost when converting the notebooks to html using Pelican, so it's still neccessary to link to the file hosted on GitHub. Either way, I'm excited about the potential this functionality offers for some other projects I have in mind for the future.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Tue, 25 Jun 2019 00:00:00 +0100</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-06-25:/jupyter-ui.html</guid><category>python</category><category>blog</category><category>pelican</category><category>ipynb</category><category>jupyter</category></item><item><title>Webscraping Metacritic</title><link>https://davebloomer.github.io/webscraping-metacritic.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In looking for interesting data sets to play with I'm often searching through Kaggle thinking 'this looks awesome, but if only it had this attribute' or 'data covering a different time period'. Most recently, this happened when looking through the &lt;a href="https://www.kaggle.com/rush4ratio/video-game-sales-with-ratings"&gt;'Kaggle data set for metacritic'&lt;/a&gt;. The natural next step was to start looking at scraping my own data, which is the process I want to cover in this post.&lt;/p&gt;
&lt;p&gt;Inevitably the html syntax for metacritic has changed from the process documented in the Kaggle kernel, so a reworking of the html parsing has been required, which also makes this an excellent excuse to get some practise in natural languages and parsing, thanks Chomsky!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-02-27:/webscraping-metacritic.html</guid><category>python</category><category>webscraping</category><category>metacritic</category></item><item><title>Visualising Geospatial Data</title><link>https://davebloomer.github.io/visualising-geospatial-data.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Probably the main reason I started studying Geology was for the opportunities that it gives you to travel. In the first instance, I thought spending two weeks in the Lake District would be a good break while studying maths and computing at college. It turned out this break would end up being 17 years, although as lovely as they are, thankfully that entire time wasn't spent in the lakes. Needless to say, I love looking at and making maps, so exploring georeferenced data is a natural progression as I'm learning about data science.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Fri, 08 Feb 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-02-08:/visualising-geospatial-data.html</guid><category>python</category><category>visualisation</category><category>geopandas</category><category>geoplot</category><category>windows</category></item><item><title>Create a blog with Anaconda, Pelican, Jupyter Notebooks (ipynb) and Github Pages (Pt. 2)</title><link>https://davebloomer.github.io/pelican-ipynb-blog-pt2.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;On to the second part of the series documenting the process of setting up this blog. This post will cover setting up GitHub pages and pushing your website, looking at options for customisation such as theme, and finally creating some batch files to streamline the process for adding a new post to the blog to avoid excessive use of terminal.&lt;/p&gt;
&lt;h3 id="GitHub-Pages-and-gbp-import"&gt;GitHub Pages and gbp-import&lt;a class="anchor-link" href="#GitHub-Pages-and-gbp-import"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;If you don't already have one, &lt;a href="https://github.com/join/"&gt;create an account&lt;/a&gt; on GitHub&lt;/li&gt;
&lt;li&gt;Create a new repository with the name &lt;code&gt;yoursite.github.io&lt;/code&gt; without creating a readme or .gitignore&lt;/li&gt;
&lt;li&gt;Return to terminal and install ghp-import using: &lt;code&gt;pip install ghp-pages&lt;/code&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-02-01:/pelican-ipynb-blog-pt2.html</guid><category>python</category><category>blog</category><category>pelican</category><category>ipynb</category><category>jupyter</category><category>git</category><category>anaconda</category></item><item><title>Visualising Algorithms with Python</title><link>https://davebloomer.github.io/visualising-algorithms-python.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;One of the themes for this term is algorithm optimisation, so I've been looking over industry standard sort and search algorithms, ever trying to minimise the '&lt;a href="https://en.wikipedia.org/wiki/Big_O_notation"&gt;Big O&lt;/a&gt;'. A classmate shared &lt;a href="https://www.reddit.com/r/woahdude/comments/78fzi7/sorting_algorithms_visualized_gifv/"&gt;these sort visualisations by morolin&lt;/a&gt;, which really help to visualise the differences in efficiency between the algorithms. While these visualisations were created in Golang, they have since been &lt;a href="https://www.makeartwithpython.com/blog/visualizing-sort-algorithms-in-python"&gt;translated in to Python by Kirk Kaiser&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's face it, writing code to sort a list isn't particularly interesting, so I wanted to see if I could impliment and visualise my own sort algorithm(s). The next step of course, was to see if similar visualisations could be created to demonstrate search algorithms..&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-01-29:/visualising-algorithms-python.html</guid><category>python</category><category>visualisation</category><category>sort</category><category>search</category></item><item><title>Create a blog with Anaconda, Pelican, Jupyter Notebooks (ipynb) and Github Pages (Pt. 1)</title><link>https://davebloomer.github.io/pelican-ipynb-blog-pt1.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Word on the town, getting in the habit of documenting your work with Jupyter notebooks is great practise. Jupyter notebooks allow you to  create and share documents containing code and rich text, to demonstrate your workflows and visualisations. On a more personal level, it gives you some freedom to be forgetful and know you'll always have an easy repository to remember how you tackled a problem in the past.&lt;/p&gt;
&lt;p&gt;The next logical step is how can I use these files to generate content for a blog, without having to reformat and convert any visualisations in to static images? And Pelican it seems, is the answer.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-01-28:/pelican-ipynb-blog-pt1.html</guid><category>python</category><category>blog</category><category>pelican</category><category>ipynb</category><category>jupyter</category><category>git</category><category>anaconda</category></item><item><title>Hello world</title><link>https://davebloomer.github.io/hello-world.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I am currently pursuing a career change in to data science after previously working as a geophysicist.&lt;/p&gt;
&lt;p&gt;As part of this process, I have decided to start blogging my progress in training to become a data scientist, not to share my progress through education, but to give myself an outlet to explore practical data science through my real world interests. What does this mean? Creating data science projects that explore the following themes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Geology, Geophysics or Georeferenced Data&lt;/li&gt;
&lt;li&gt;Gaming (Video and Modern Board Games)&lt;/li&gt;
&lt;li&gt;Design and Visualisation (Infographics)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first couple of posts I'm working on are how to set up a free blog using Jupyter notebooks with Anaconda, which is a slightly different approach to lots of the existing guides online. Then following implementing a board game in my coursework, &lt;a href="https://en.wikipedia.org/wiki/The_Three_Musketeers"&gt;The Three Musketeers&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Dave Bloomer</dc:creator><pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:davebloomer.github.io,2019-01-27:/hello-world.html</guid><category>misc</category></item></channel></rss>